{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../source\")\n",
    "# sys.path.append(\"../source/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.ptz_dataset import PTZImageDataset, get_position_datetime_from_labels\n",
    "from transforms import make_transforms\n",
    "from gen_embed import generate_embedding\n",
    "from utils.analysis_viz import read_train_loss, flatten, read_fname_embed_from_h5, sort_by_time_from_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/Users/yufengluo/Research/anl/su24/trainings/workflow\")\n",
    "img_dir = root_dir / \"collected_imgs\"\n",
    "# code_dir = Path(\"/app/PTZJEPA\")\n",
    "model_dir = root_dir / \"world_models/model_43\"\n",
    "infer_dir = model_dir / \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PTZImageDataset(img_dir, transform=make_transforms(crop_size=512), return_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train, header = read_train_loss(model_dir / \"jepa.csv\")\n",
    "df = pd.DataFrame(flatten(all_train), columns=header, dtype=float)\n",
    "x_axis = np.array([row.epoch + row.itr/df.query(\"epoch==@row.epoch\").itr.max() for row in df.itertuples()],\n",
    "                  dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_axis, df['loss'], \"-\")\n",
    "for i in np.unique(df.restart):\n",
    "    plt.vlines(x_axis[df.query(\"restart==@i\").index[-1]], ymin=0, ymax=df['loss'].max()/2, color='r', linestyles='dashed')\n",
    "# plt.vlines(x_axis[df.query(\"restart==0\").index[-1]], ymin=0, ymax=300, color='r', linestyles='dashed')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.prepare_dataset import verify_image\n",
    "\n",
    "\n",
    "for fp in img_dir.glob(\"*.jpg\"):\n",
    "    verify_image(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(img_dir.glob(\"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_embedding(model_dir / \"params-ijepa.yaml\", model_dir / \"jepa-latest.pt\",\n",
    "                   img_dir, infer_dir, world_model=True, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(infer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = np.load(infer_dir / \"rewards_predictor.npy\", allow_pickle=True)\n",
    "reward = np.mean(reward, axis=1)\n",
    "reward = reward.reshape(-1, batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(infer_dir / \"labels.txt\") as f:\n",
    "    labels = [l.strip() for l in f if l.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fnames, pred_embeds = read_fname_embed_from_h5(infer_dir / \"embeds_predictor.h5\")\n",
    "contx_fnames, contx_embeds = read_fname_embed_from_h5(infer_dir / \"embeds_contx_encoder.h5\")\n",
    "target_fnames, target_embeds = read_fname_embed_from_h5(infer_dir / \"embeds_target_encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embeds[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embeds = np.mean(pred_embeds, axis=2)\n",
    "contx_embeds = np.mean(contx_embeds, axis=2)\n",
    "target_embeds = np.mean(target_embeds, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embed_sort, *pred_meta = sort_by_time_from_label(pred_embeds, pred_fnames)\n",
    "contx_embed_sort, *contx_meta = sort_by_time_from_label(contx_embeds, contx_fnames)\n",
    "target_embed_sort, *target_meta = sort_by_time_from_label(target_embeds, target_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(pred_meta, index=[\"fnames\", \"pos\", \"time\"]).T\n",
    "df_contx = pd.DataFrame(contx_meta, index=[\"fnames\", \"pos\", \"time\"]).T\n",
    "df_target = pd.DataFrame(target_meta, index=[\"fnames\", \"pos\", \"time\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embed_avg = pred_embed_sort\n",
    "contx_embed_avg = contx_embed_sort\n",
    "target_embed_avg = target_embed_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_embed_avg = np.mean(pred_embed_sort, axis=2)\n",
    "# contx_embed_avg = np.mean(contx_embed_sort, axis=2)\n",
    "# target_embed_avg = np.mean(target_embed_sort, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_embed_avg.shape, contx_embed_avg.shape, target_embed_avg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate the prediction results\n",
    "\n",
    "The order of context & pred images are 0000 1111 2222 3333 .... \n",
    "\n",
    "The order of target images is 0123 0123 0123 ....\n",
    "\n",
    "So the predictor should have a behavior closely resemble the target images,\n",
    "but not exactly the same.\n",
    "\n",
    "The zero norm values mean that the target and context encoders are producing the\n",
    "same output for the same image. This is just a sanity check to make sure the\n",
    "encoders are working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(contx_embed_avg[:, 0] - contx_embed_avg[:, batch_size-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linalg.norm(target_embed_avg[0, :] - target_embed_avg[batch_size-2, :]))\n",
    "print(linalg.norm(target_embed_avg[0, :] - target_embed_avg[batch_size-1, :]))\n",
    "print(linalg.norm(target_embed_avg[0, :] - target_embed_avg[batch_size, :]))\n",
    "# print(linalg.norm(target_embed_avg[5, :] - target_embed_avg[7, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linalg.norm(pred_embed_avg[:, 0] - pred_embed_avg[:, 3]))\n",
    "print(linalg.norm(pred_embed_avg[0, :] - pred_embed_avg[3, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now downsample the embeddings based on the ordering\n",
    "samp_target_embed = target_embed_avg[::batch_size, :]\n",
    "samp_target_embed = samp_target_embed.reshape(-1, samp_target_embed.shape[-1])\n",
    "samp_contx_embed = contx_embed_avg[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(samp_target_embed - samp_contx_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pca_tsne_transform(embeds, pca_components=50):\n",
    "    embeds_scaled = StandardScaler().fit_transform(embeds)\n",
    "    # embeds_feat = VarianceThreshold(threshold=0.001).fit_transform(embeds_scaled)\n",
    "    embeds_feat = embeds_scaled\n",
    "    embeds_pca = PCA(n_components=pca_components, svd_solver='auto').fit_transform(embeds_feat)\n",
    "    embeds_tsne = TSNE(n_components=2, learning_rate='auto', init='pca', perplexity=50, n_jobs=-1, random_state=0).fit_transform(embeds_pca)\n",
    "    return embeds_tsne, embeds_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_contx_embeds = scale_pca_tsne_transform(samp_contx_embed)\n",
    "# trans_pred_embeds = scale_pca_tsne_transform(pred_embed_avg)\n",
    "trans_target_embeds = scale_pca_tsne_transform(samp_target_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_self = np.zeros((pred_embed_avg.shape[0], pred_embed_avg.shape[-1]))\n",
    "reward_self = np.zeros((reward.shape[0], reward.shape[-1]))\n",
    "# 3 per batch\n",
    "pred_dist_one = np.zeros((int(pred_embed_avg.shape[0]*3/4), pred_embed_avg.shape[-1]))\n",
    "reward_one = np.zeros((int(reward.shape[0]*3/4), reward.shape[-1]))\n",
    "# 2 per batch\n",
    "pred_dist_two = np.zeros((int(pred_embed_avg.shape[0]/2), pred_embed_avg.shape[-1]))\n",
    "reward_two = np.zeros((int(reward.shape[0]/2), reward.shape[-1]))\n",
    "# 1 per batch\n",
    "pred_dist_three = np.zeros((int(pred_embed_avg.shape[0]/4), pred_embed_avg.shape[-1]))\n",
    "reward_three = np.zeros((int(reward.shape[0]/4), reward.shape[-1]))\n",
    "for i, arr in enumerate(pred_embed_avg):\n",
    "    pred_self[i] = arr[i % batch_size]\n",
    "    reward_self[i] = reward[i, i % batch_size]\n",
    "    if i % batch_size == 3:\n",
    "        continue\n",
    "    remind = i % batch_size\n",
    "    pred_dist_one[(i//batch_size)*3 + remind] = arr[1+remind]\n",
    "    reward_one[(i//batch_size)*3+remind] = reward[i, 1+remind]\n",
    "    if i % batch_size == 2:\n",
    "        continue\n",
    "    pred_dist_two[(i//batch_size)*2 + remind] = arr[2+remind]\n",
    "    reward_two[(i//batch_size)*2+remind] = reward[i, 2+remind]\n",
    "    if i % batch_size == 1:\n",
    "        continue\n",
    "    pred_dist_three[i//batch_size] = arr[3]\n",
    "    reward_three[i//batch_size] = reward[i, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_pred_one = scale_pca_tsne_transform(pred_dist_one)\n",
    "trans_pred_two = scale_pca_tsne_transform(pred_dist_two)\n",
    "trans_pred_three = scale_pca_tsne_transform(pred_dist_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_pred_self = scale_pca_tsne_transform(pred_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(12, 15))\n",
    "plt.set_cmap(\"viridis\")\n",
    "ax = ax.ravel()\n",
    "ax[0].scatter(trans_contx_embeds[0][:, 0], trans_contx_embeds[0][:, 1], s=2, label=\"context\")\n",
    "ax[0].scatter(trans_target_embeds[0][:, 0], trans_target_embeds[0][:, 1], s=2, alpha=0.5, label=\"target\")\n",
    "ax[0].legend()\n",
    "ax[0].set_aspect(\"equal\")\n",
    "\n",
    "vmin = -0.05\n",
    "vmax = 0.05\n",
    "ax[1].scatter(trans_pred_self[0][:, 0], trans_pred_self[0][:, 1], s=2, label=\"self\",\n",
    "              c=reward_self.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[1].set_aspect(\"equal\")\n",
    "ax[1].legend()\n",
    "ax[1].set_xlim([-80, 80])\n",
    "ax[1].set_ylim([-80, 80])\n",
    "\n",
    "\n",
    "ax[2].scatter(trans_pred_one[0][:, 0], trans_pred_one[0][:, 1], s=2, label=\"1 step\",\n",
    "              c=reward_one.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[2].scatter(trans_pred_two[0][:, 0], trans_pred_two[0][:, 1], s=2, label=\"2 step\",\n",
    "              c=reward_two.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[2].scatter(trans_pred_three[0][:, 0], trans_pred_three[0][:, 1], s=2, label=\"3 step\",\n",
    "              c=reward_three.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[2].legend()\n",
    "ax[2].set_aspect(\"equal\")\n",
    "ax[2].set_xlim([-80, 80])\n",
    "ax[2].set_ylim([-80, 80])\n",
    "fig.colorbar(ax[2].collections[0], ax=ax[2])\n",
    "\n",
    "ax[3].scatter(trans_pred_one[0][:, 0], trans_pred_one[0][:, 1], s=2, label=\"1 step\",\n",
    "              c=reward_one.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[3].legend()\n",
    "ax[3].set_aspect(\"equal\")\n",
    "ax[3].set_xlim([-80, 80])\n",
    "ax[3].set_ylim([-80, 80])\n",
    "\n",
    "ax[4].scatter(trans_pred_two[0][:, 0], trans_pred_two[0][:, 1], s=2, label=\"2 step\",\n",
    "              c=reward_two.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[4].legend()\n",
    "ax[4].set_aspect(\"equal\")\n",
    "ax[4].set_xlim([-80, 80])\n",
    "ax[4].set_ylim([-80, 80])\n",
    "\n",
    "ax[5].scatter(trans_pred_three[0][:, 0], trans_pred_three[0][:, 1], s=2, label=\"3 step\",\n",
    "              c=reward_three.flatten(), vmin=vmin, vmax=vmax)\n",
    "ax[5].legend()\n",
    "ax[5].set_aspect(\"equal\")\n",
    "ax[5].set_xlim([-80, 80])\n",
    "ax[5].set_ylim([-80, 80])\n",
    "\n",
    "# ax[5].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reward.flatten(), bins=np.arange(vmin, vmax, 0.01))\n",
    "# plt.xlim([12, 13])\n",
    "plt.ylabel(\"count\")\n",
    "plt.xlabel(\"reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reward.ravel(), columns=[\"reward\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reward_one).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reward_two).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reward_three).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reward_self).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fnames = np.array(pred_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(reward_one < 10)[0]\n",
    "ori_fnames = pred_fnames[idx // 3 * batch_size]\n",
    "comp_fnames = pred_fnames[idx // 3 * batch_size + 1] # always the next image for step 1\n",
    "for pick_idx in range(5):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "    ax[0].imshow(plt.imread(img_dir / (ori_fnames[pick_idx] + \".jpg\")))\n",
    "    ax[0].set_title(ori_fnames[pick_idx])\n",
    "    ax[1].imshow(plt.imread(img_dir / (comp_fnames[pick_idx] + \".jpg\")))\n",
    "    ax[1].set_title(comp_fnames[pick_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(reward_two < 10)[0]\n",
    "ori_fnames = pred_fnames[idx // 2 * batch_size]\n",
    "comp_fnames = pred_fnames[idx // 2 * batch_size + 2]\n",
    "for pick_idx in range(10):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "    ax[0].imshow(plt.imread(img_dir / (ori_fnames[pick_idx] + \".jpg\")))\n",
    "    ax[0].set_title(ori_fnames[pick_idx])\n",
    "    ax[1].imshow(plt.imread(img_dir / (comp_fnames[pick_idx] + \".jpg\")))\n",
    "    ax[1].set_title(comp_fnames[pick_idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(reward_three < 10)[0]\n",
    "ori_fnames = pred_fnames[idx // 1 * batch_size]\n",
    "comp_fnames = pred_fnames[idx // 1 * batch_size + 3]\n",
    "for i in range(len(idx)):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "    ax[0].imshow(plt.imread(img_dir / (ori_fnames[i] + \".jpg\")))\n",
    "    ax[0].set_title(ori_fnames[i])\n",
    "    ax[1].imshow(plt.imread(img_dir / (comp_fnames[i] + \".jpg\")))\n",
    "    ax[1].set_title(comp_fnames[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
